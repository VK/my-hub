{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a804790a-856b-4c5c-85eb-aed96b5007e1",
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "import mixturemapping as mm\n",
    "import numpy as np\n",
    "import plotly.express as px\n",
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c7168158-8c88-4cac-90e8-5ed3e2fee539",
   "metadata": {},
   "outputs": [],
   "source": [
    "mixN = 3 #dimension of Gaussian Mixture\n",
    "inputMixM = 2 #dimension of single Gaussian in the input mixture\n",
    "outputMixM = 3 #dimension of a single Gaussian in the output mixture\n",
    "sampleSize = 200\n",
    "batchSize = 50\n",
    "dataType = tf.float32"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d6afb446-49c3-493c-9aa9-e80810953749",
   "metadata": {},
   "outputs": [],
   "source": [
    "def __getSamples(mapFunc,\n",
    "                 mixN,\n",
    "                 inputMixM,\n",
    "                 outputMixM,\n",
    "                 sampleSize,\n",
    "                 ):\n",
    "\n",
    "    totalSamplesN = 100\n",
    "\n",
    "    # compute an array of weights of the different mixture components\n",
    "    w = np.random.uniform(low=0, high=1, size=(totalSamplesN, mixN))\n",
    "    w = w / np.expand_dims(np.sum(w, axis=1), 1)\n",
    "\n",
    "    # fill the initial values of the distributions\n",
    "    trainFeatures = {\n",
    "        \"InputMean\": np.random.uniform(high=20.0, size=(totalSamplesN, 1, inputMixM)) + np.random.uniform(high=10, size=(totalSamplesN, mixN, inputMixM)),\n",
    "        \"InputStdDev\": np.random.uniform(high=0.5, size=(totalSamplesN, 1, inputMixM)) + np.random.uniform(high=0.1, size=(totalSamplesN, mixN, inputMixM)),\n",
    "        \"InputWeights\": w,\n",
    "    }\n",
    "\n",
    "    # create a mapped set of training and validation samples\n",
    "    TrainMeanSamplesArray = []\n",
    "    TrainStdDevSamplesArray = []\n",
    "    TrainWeightsSamplesArray = []\n",
    "    TrainSamplesArray = []\n",
    "\n",
    "    for i in range(totalSamplesN):\n",
    "\n",
    "        mix = mm.utils.getSkleanGM(\n",
    "            trainFeatures[\"InputWeights\"][i], trainFeatures[\"InputMean\"][i], trainFeatures[\"InputStdDev\"][i])\n",
    "\n",
    "        # copy the input to make the right length\n",
    "        TrainMeanSamplesArray.append(np.transpose(\n",
    "            [trainFeatures[\"InputMean\"][i] for x in range(sampleSize)]))\n",
    "        TrainStdDevSamplesArray.append(np.transpose(\n",
    "            [trainFeatures[\"InputStdDev\"][i] for x in range(sampleSize)]))\n",
    "        TrainWeightsSamplesArray.append(np.transpose(\n",
    "            [trainFeatures[\"InputWeights\"][i] for x in range(sampleSize)]))\n",
    "\n",
    "        TrainSamplesArray.append(np.transpose(\n",
    "            [mapFunc(x) for x in mix.sample(sampleSize)[0]]))\n",
    "\n",
    "    trainFeatures[\"TrainSamples\"] = np.reshape(np.transpose(\n",
    "        TrainSamplesArray, [0, 2, 1]), [sampleSize*totalSamplesN, outputMixM])\n",
    "\n",
    "    trainFeatures[\"TrainMean\"] = np.reshape(np.transpose(TrainMeanSamplesArray, [\n",
    "                                            0, 3, 2, 1]), [sampleSize*totalSamplesN, mixN, inputMixM])\n",
    "    trainFeatures[\"TrainStdDev\"] = np.reshape(np.transpose(TrainStdDevSamplesArray, [\n",
    "        0, 3, 2, 1]), [sampleSize*totalSamplesN, mixN, inputMixM])\n",
    "    trainFeatures[\"TrainWeights\"] = np.reshape(np.transpose(\n",
    "        TrainWeightsSamplesArray, [0, 2, 1]), [sampleSize*totalSamplesN, mixN])\n",
    "\n",
    "    trainFeatures[\"GroupedSamples\"] = np.array(TrainSamplesArray)\n",
    "    return trainFeatures\n",
    "\n",
    "\n",
    "def getSimpleLinearA(mixN,\n",
    "                     inputMixM,\n",
    "                     outputMixM,\n",
    "                     sampleSize,\n",
    "                     ):\n",
    "    def mapFunc(x):\n",
    "        \"\"\"\n",
    "        we assume x to be a single sample vec, which is transformed to a point in the output distribution\n",
    "        \"\"\"\n",
    "        return np.array([x[0]*0.9 + .9, -x[1]*0.9 - 0.3, -x[0]*0.5 + .2]) + np.random.normal(scale=.1, size=3)\n",
    "    return {\n",
    "        \"trainFeatures\": __getSamples(mapFunc,\n",
    "                                      mixN,\n",
    "                                      inputMixM,\n",
    "                                      outputMixM,\n",
    "                                      sampleSize,\n",
    "                                      ),\n",
    "                                      \"testFeatures\": {\n",
    "                                          \"mapping_kernel\": [[0.9, 0, -0.5], [0.0, -0.9, 0]],\n",
    "                                          \"mapping_bias\": [0.9, -0.3, 0.2],\n",
    "                                          \"cov_std\": [.1, 0.1, 0.1],\n",
    "                                      }\n",
    "\n",
    "    }"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5ed6b5c4-0aab-47cd-80d0-3eda03a550f9",
   "metadata": {},
   "outputs": [],
   "source": [
    "example_data = getSimpleLinearA(\n",
    "    mixN,\n",
    "    inputMixM,\n",
    "    outputMixM,\n",
    "    sampleSize\n",
    ")\n",
    "trainFeatures = example_data[\"trainFeatures\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ed07536a-f677-4dea-811c-3a62ce331580",
   "metadata": {},
   "outputs": [],
   "source": [
    "tf.keras.backend.clear_session()\n",
    "\n",
    "\n",
    "with tf.name_scope(\"WaferGMM\"):\n",
    "    inMean = tf.keras.Input(shape=(mixN, inputMixM), name=\"Mean\", dtype=dataType)\n",
    "    inStdDev = tf.keras.Input(shape=(mixN, inputMixM), name=\"StdDev\", dtype=dataType)\n",
    "    inWeight = tf.keras.Input(shape=(mixN), name=\"Weight\", dtype=dataType)\n",
    "\n",
    "with tf.name_scope(\"SampleInput\"):\n",
    "    inTsamples = tf.keras.Input(shape=(outputMixM), name=\"TrainSamples\", dtype=dataType)\n",
    "    \n",
    "with tf.name_scope(\"CoreModel\"):\n",
    "    covALayer = mm.layers.TrainableCovMatrix(outputMixM, name=\"CovA\")\n",
    "    covA = covALayer(inMean)\n",
    "\n",
    "    mappingLayer = mm.layers.LinearMapping(outputMixM, name=\"Mapping\", dtype=dataType)\n",
    "    newDist = mappingLayer({'x': inMean, 'stdDev': inStdDev, 'w': inWeight, 'covA': covA})\n",
    "\n",
    "    distLayer = mm.layers.Distribution(dtype=dataType, regularize_cov_epsilon=0.95)\n",
    "\n",
    "    dist = distLayer(newDist)\n",
    "\n",
    "with tf.name_scope(\"Outputs\"):\n",
    "    outputMeans = dist.mean()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3f930514-0f57-4965-969e-a922fb00c62d",
   "metadata": {},
   "outputs": [],
   "source": [
    "model = tf.keras.Model(inputs=[inMean, inStdDev, inWeight, inTsamples], outputs=dist)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "46969f7b-4350-435a-9cb3-3668fa6abdb9",
   "metadata": {},
   "outputs": [],
   "source": [
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0f021819-4cee-46a7-bb2c-adff9b3acfad",
   "metadata": {},
   "outputs": [],
   "source": [
    "mappingLayer.sampling_ON()\n",
    "\n",
    "optimizer = tf.optimizers.Adam()\n",
    "\n",
    "initial_learning_rate = 0.01\n",
    "optimizer = tf.optimizers.Adam(learning_rate=initial_learning_rate)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "08c2959a-e964-4f44-9f79-b03d7f01ac75",
   "metadata": {},
   "outputs": [],
   "source": [
    "model.compile(optimizer=optimizer, loss=distLayer.sample_loss(inTsamples))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a0ab9db3-f19a-4079-b0c8-4bd391d853e9",
   "metadata": {},
   "outputs": [],
   "source": [
    "callbacks = [\n",
    "    tf.keras.callbacks.EarlyStopping(\n",
    "        # Stop training when `val_loss` is no longer improving\n",
    "        monitor=\"val_loss\",\n",
    "        # \"no longer improving\" being defined as \"no better than 1e-2 less\"\n",
    "        min_delta=1e-2,\n",
    "        patience=20,\n",
    "        verbose=1,\n",
    "        restore_best_weights=True\n",
    "    )\n",
    "]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "04181562-45e7-4f43-b9f8-d664547ca217",
   "metadata": {},
   "outputs": [],
   "source": [
    "hist = model.fit([\n",
    "    trainFeatures[\"TrainMean\"],\n",
    "    trainFeatures[\"TrainStdDev\"],\n",
    "    trainFeatures[\"TrainWeights\"],\n",
    "    trainFeatures[\"TrainSamples\"]],\n",
    "    shuffle=True, validation_split=0.1, \n",
    "    epochs=500, batch_size=100, \n",
    "    verbose=False, use_multiprocessing=False, \n",
    "    callbacks=callbacks,\n",
    "    )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7c72cffe-1552-4f0f-99d7-0f3c5fe4de40",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_train = pd.DataFrame(hist.history[\"loss\"], columns=[\"loss\"])\n",
    "df_train[\"type\"] = \"train\"\n",
    "df_val = pd.DataFrame(hist.history[\"val_loss\"], columns=[\"loss\"])\n",
    "df_val[\"type\"] = \"val\"\n",
    "\n",
    "px.line(pd.concat([df_train, df_val]), y=\"loss\", color=\"type\", log_y=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a2441923-5f7d-41ac-ac9d-c7da1f92848f",
   "metadata": {},
   "outputs": [],
   "source": [
    "mappingLayer.sampling_OFF()\n",
    "\n",
    "modelSamples = tf.transpose(dist.sample(100), [1, 2, 0])\n",
    "model2 = tf.keras.Model(inputs=[inMean, inStdDev, inWeight], outputs=modelSamples)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "56d1392c-4999-42db-9e57-86096e4db1b5",
   "metadata": {},
   "outputs": [],
   "source": [
    "res = model2.predict([trainFeatures[\"InputMean\"], trainFeatures[\"InputStdDev\"], trainFeatures[\"InputWeights\"]])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "206268a5-7568-409f-bfe6-9e113dac50cb",
   "metadata": {},
   "outputs": [],
   "source": [
    "idx = 13\n",
    "\n",
    "df_pred = pd.DataFrame(res[idx].T, columns=[\"x\", \"y\", \"z\"])\n",
    "df_pred[\"type\"] = \"pred\"\n",
    "df_true = pd.DataFrame(trainFeatures[\"GroupedSamples\"][idx].T, columns=[\"x\", \"y\", \"z\"])\n",
    "df_true[\"type\"] = \"true\"\n",
    "\n",
    "px.scatter_3d(pd.concat([df_pred, df_true]), x=\"x\", y=\"y\", z=\"z\", color=\"type\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cc0807df-ea06-45f5-9f40-5c79b2b4932b",
   "metadata": {},
   "outputs": [],
   "source": [
    "delta = tf.keras.backend.eval(\n",
    "    mappingLayer.kernel.mean() - example_data[\"testFeatures\"][\"mapping_kernel\"]\n",
    ")\n",
    "print(delta)\n",
    "max_delta = np.max(np.abs(delta))\n",
    "print(max_delta)\n",
    "assert max_delta < 0.05, \"Mapping slope off\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "323295d1-9e2c-42ab-b1c5-c4e493262c9b",
   "metadata": {},
   "outputs": [],
   "source": [
    "delta = tf.keras.backend.eval(\n",
    "    mappingLayer.bias.mean() - example_data[\"testFeatures\"][\"mapping_bias\"]\n",
    ")\n",
    "print(delta)\n",
    "max_delta = np.max(np.abs(delta))\n",
    "print(max_delta)\n",
    "assert max_delta < 0.05, \"mapping bias off\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d82de9d8-38cb-44e5-81a2-584452fa20f6",
   "metadata": {},
   "outputs": [],
   "source": [
    "delta = tf.keras.backend.eval(\n",
    "    covALayer.spread[0] - example_data[\"testFeatures\"][\"cov_std\"]\n",
    ")\n",
    "print(delta)\n",
    "max_delta = np.max(np.abs(delta))\n",
    "print(max_delta)\n",
    "assert max_delta < 0.05, \"distribution spread off\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "74501198-c7ba-4061-9cd1-0520362bad16",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
